----- Skeem Simulator Design Document -----
[About]
This document describes the design of the simulator used to test algorithms
for Skeem as to determine their usability in the development of the application.
This simulator is inspired by:
https://github.com/sausheong/founders/blob/master/founders.ipynb

The simulator runs implementation of the scheduling algorithms over random or
predefined data and generates statistics over their their 
- quaility of output (generated schedule), 
- time taken/memory used 
- scalability (ie how it scales over large data sets.)
The simulator would also produce data that can be used to benchmark algorithms 
against each other. This allows us to determine an optimal algorithm for the 
Scheduler in Skeem.

[Design]
skeem.py - Data Model Objects replicating the ones to be implemented in Skeem
    Ref: doc/object.txt
    Note that repetition and tags  are implemented on a proof on concept basis 
    and are not actually used in the simulation due to development timing 
    constriant.
algorithm.py - Implementations of the algorithms to be benchmarked and tested
    - Defines concrete subclasses of the scheduling algorithm that contain the
      implementation of each algorithm used in the simulator
    - provides the array of algorithms that defines the algorithms used in the
      simulators
sim.py  - Generates data sets and runs thems over the algorithms, recording 
          statistics and storing them in a file
        - Uses the cprofile module to measure program program perfomance using
          cprofile.run writing the output into a file.
        - Leverages on concurrency to run simulations in parrallel to speed 
          things up.
        - Uses random module to generate random test cases
display.py  - Display statistics files generated by sim.py in a visual plotted
              format that faciliates the analysis of data.
            - Uses the pstats module to read perfomance statics generated by
              sim.py
            - Slices schedule at a certain stop date to measure schedule 
              perfomance
              under limited time condtitions. 
            - Prints algorithms perfomance profile if requested.
            - Displays the following metrics to determine algorithm perfomance
                - Time taken to schedule
                - Percentage of completed tasks over all weights
                - Percentage of completed weights 
                - Percentage of tasks completed before deadline
                - Balance of the tasks -  standard time deviation between the 
                  tasks
                
[Simulator Implementation]
sim.py  
- Uses getopt to parse arguments and options
- Loads algorithms and skeem objects
- Generate test case
- make directory and write test case
+ foreach algorithm
    - make a copy of the test case
    - run the test case on the algorithm while profiling the run using cprofile
    - concurrent queue that runs the simulations concurrently
    - write output to output directory
-- Options --
-v Verbrose mode - debugging infomation
-j <threads> - Number of threads to use while simulating
            - use -j 1 for debugging to show error messages
-t <tests> - Number of number tests cases to test per algorithm
-l <size> - Size of the test cases to run.
-o <directory> - put the output in this directory, else by default, sim_out

--- Output ---
dictionary object in a pickled file named in the format <test_case>.<algorithm>
- profile - profiling from cprofile as string?
- schedule object generated as array of schedulables

display.py
- Uses getopt ot parse arguments and options
- Uses output from sim.py to display meanful infomation used to determine which
  algorithm is optiomal for use in skeem app.
- Display for each test case
    - Display for each algorithm
        - Time taken to schedule -pyplot bar graph time taken/ size of test case
        - Percentage of completed tasks over all weights - pyplot stopdate
        - Percentage of completed weights  - pyplot stopdate
        - Percentage of tasks completed before deadline - pyplot stopdate
        - Balance of the tasks -  standard time deviation between the 
          task
- Interative display command with prompt and the following commands
- l - list test cases with id
- a - list algorithms with id 
- t - display graph plotting processing time taken to schedule for each 
     algorithm
- T - display graph plotting average duration of each task scheduled. 
- w - display graph plotting weights complete for each algorithm.
- d - display graph plotting task complete before deadline for each algorithm.
- b - display graph plotting standard deviation between each task for each
      each algorithm.
- p <test case> <algorithm> - print perfomance profile for algorithm and test 
                              case.
- i <test case> <algorithm> - print itinerary generated by algorithm from test 
                              case.
- c <percentage> - update constriants
